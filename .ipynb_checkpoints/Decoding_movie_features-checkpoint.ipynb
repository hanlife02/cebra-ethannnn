{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4cf927",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib as jl\n",
    "import torch\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import cebra.datasets\n",
    "from cebra import CEBRA\n",
    "import cebra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd14fb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    DEVICE = \"cuda\"\n",
    "else:\n",
    "    DEVICE = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc6335a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从 [“VISp”, “VISpm”, “VISam”, “VISrl”, “VISal”, “VISl”] 中设置“cortex”\n",
    "# 从 [111, 222, 333, 444, 555] 中设置“seed”\n",
    "# 从 [10, 30, 50, 100, 200, 400, 600, 800, 900, 1000] 中设置“num_neurons”\n",
    "# 数据集位于data/allen/allen_movie1_neuropixel下\n",
    "\n",
    "cortex = 'VISp'\n",
    "seed=333\n",
    "num_neurons = 800\n",
    "\n",
    "ca_train = cebra.datasets.init(f'allen-movie-one-ca-{cortex}-{num_neurons}-train-10-{seed}')\n",
    "np_train = cebra.datasets.init(f'allen-movie-one-neuropixel-{cortex}-{num_neurons}-train-10-{seed}')\n",
    "joint_train = cebra.datasets.init(f'allen-movie-one-ca-neuropixel-{cortex}-{num_neurons}-train-10-{seed}')\n",
    "\n",
    "ca_test = cebra.datasets.init(f'allen-movie-one-ca-{cortex}-{num_neurons}-test-10-{seed}')\n",
    "np_test = cebra.datasets.init(f'allen-movie-one-neuropixel-{cortex}-{num_neurons}-test-10-{seed}')\n",
    "joint_test = cebra.datasets.init(f'allen-movie-one-ca-neuropixel-{cortex}-{num_neurons}-test-10-{seed}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fd204c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "ax1= plt.subplot(1,2,1)\n",
    "ax1.imshow(ca_train.neural.cpu().numpy()[:900].T, aspect = 'auto', vmax = 1, vmin = 0, cmap ='gray_r')\n",
    "ax1.set_ylabel('# Neurons')\n",
    "ax1.set_xlabel('Time (s)')\n",
    "ax1.set_xticks(np.linspace(0,900, 4))\n",
    "ax1.set_xticklabels(np.linspace(0,30, 4))\n",
    "ax1.set_title('Ca spikes')\n",
    "ax2= plt.subplot(1,2,2)\n",
    "ax2.imshow(np_train.neural.cpu().numpy()[:3600].T, aspect = 'auto', vmax = 1, vmin = 0, cmap ='gray_r')\n",
    "ax2.set_ylabel('# Neurons')\n",
    "ax2.set_xlabel('Time (s)')\n",
    "ax2.set_xticks(np.linspace(0,3600, 4))\n",
    "ax2.set_xticklabels(np.linspace(0,30, 4))\n",
    "ax2.set_title('Neuropixels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb22faab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dino_tsne = TSNE(n_components = 2)\n",
    "dino_tsne_viz = dino_tsne.fit_transform(ca_train.index[:900,:])\n",
    "\n",
    "fig = plt.figure(figsize = (5,5))\n",
    "plt.scatter(dino_tsne_viz[:,0], dino_tsne_viz[:,1], cmap = 'magma', c = np.arange(900))\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1aaf056",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helper functions to define CEBRA solvers\n",
    "\n",
    "def single_session_solver(data_loader, **kwargs):\n",
    "    \"\"\"Train a single session CEBRA model.\"\"\"\n",
    "    norm = True\n",
    "    if kwargs['distance'] == 'euclidean':\n",
    "        norm = False\n",
    "    data_loader.to(kwargs['device'])\n",
    "    model = cebra.models.init(kwargs['model_architecture'], data_loader.dataset.input_dimension,\n",
    "                              kwargs['num_hidden_units'],\n",
    "                              kwargs['output_dimension'], norm).to(kwargs['device'])\n",
    "    data_loader.dataset.configure_for(model)\n",
    "    if kwargs['distance'] == 'euclidean':\n",
    "        criterion = cebra.models.InfoMSE(temperature=kwargs['temperature'])\n",
    "    elif kwargs['distance'] == 'cosine':\n",
    "        criterion = cebra.models.InfoNCE(temperature=kwargs['temperature'])\n",
    "    optimizer = torch.optim.Adam(itertools.chain(model.parameters(), criterion.parameters()), lr=kwargs['learning_rate'])\n",
    "    return cebra.solver.SingleSessionSolver(model=model,\n",
    "                                            criterion=criterion,\n",
    "                                            optimizer=optimizer,\n",
    "                                            tqdm_on=kwargs['verbose'])\n",
    "\n",
    "def multi_session_solver(data_loader, **kwargs):\n",
    "    norm = True\n",
    "    if kwargs['distance'] == 'euclidean':\n",
    "        norm = False\n",
    "    for dataset in data_loader.dataset.iter_sessions():\n",
    "        dataset.to(kwargs['device'])\n",
    "\n",
    "    model = torch.nn.ModuleList([\n",
    "        cebra.models.init(m, dataset.input_dimension,\n",
    "                          kwargs['num_hidden_units'], kwargs['output_dimension'], norm)\n",
    "        for dataset, m in zip(data_loader.dataset.iter_sessions(), kwargs['model_architecture'])\n",
    "    ]).to(kwargs['device'])\n",
    "\n",
    "    for m in model:\n",
    "        m.to(kwargs['device'])\n",
    "    for n, dataset in enumerate(data_loader.dataset.iter_sessions()):\n",
    "        dataset.configure_for(model[n])\n",
    "    if kwargs['distance'] == 'euclidean':\n",
    "        criterion = cebra.models.InfoMSE(temperature=kwargs['temperature'])\n",
    "    elif kwargs['distance'] == 'cosine':\n",
    "        criterion = cebra.models.InfoNCE(temperature=kwargs['temperature'])\n",
    "    optimizer = torch.optim.Adam(itertools.chain(model.parameters(), criterion.parameters()), lr=kwargs['learning_rate'])\n",
    "    return cebra.solver.MultiSessionSolver(model=model,\n",
    "                                           criterion=criterion,\n",
    "                                           optimizer=optimizer,\n",
    "                                           tqdm_on=kwargs['verbose'])\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_emissions(model, dataset):\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda\"\n",
    "    else:\n",
    "        device = \"cpu\"\n",
    "    model.to(device)\n",
    "    dataset.configure_for(model)\n",
    "    return model(dataset[torch.arange(len(dataset))].to(device)).cpu().numpy()\n",
    "\n",
    "def _compute_emissions_single(solver, dataset):\n",
    "    return get_emissions(solver.model, dataset)\n",
    "\n",
    "def _compute_emissions_multi(solver, dataset):\n",
    "\n",
    "    return {\n",
    "        i :\n",
    "            get_emissions(model, session)\n",
    "            for i, (model, session) in enumerate(zip(solver.model, dataset.iter_sessions()))\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3f0470",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_steps = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac24dcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_loader = cebra.data.ContinuousDataLoader(ca_train, num_steps = train_steps, batch_size = 512, conditional = 'time_delta', time_offset =1)\n",
    "np_loader = cebra.data.ContinuousDataLoader(np_train, num_steps = train_steps, batch_size = 512, conditional = 'time_delta', time_offset = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ece15b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cebra_ca = single_session_solver(data_loader = ca_loader, model_architecture = 'offset1-model',\n",
    "                 distance = 'cosine', num_hidden_units = 128, output_dimension = 128,\n",
    "                verbose = True, device = DEVICE, temperature = 1, learning_rate = 3e-4)\n",
    "\n",
    "cebra_np = single_session_solver(data_loader = np_loader, model_architecture = 'resample1-model',\n",
    "                 distance = 'cosine', num_hidden_units = 128, output_dimension = 128,\n",
    "                verbose = True, device = DEVICE, temperature = 1, learning_rate = 3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c682d30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cebra_ca.fit(ca_loader)\n",
    "cebra_ca_emb = _compute_emissions_single(cebra_ca, ca_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df679343",
   "metadata": {},
   "outputs": [],
   "source": [
    "cebra_np.fit(np_loader)\n",
    "cebra_np_emb = _compute_emissions_single(cebra_np, np_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308f057c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (12,5))\n",
    "\n",
    "ax1 = plt.subplot(121)\n",
    "ax1.set_title('Ca')\n",
    "ax1.scatter(cebra_ca_emb[:,0], cebra_ca_emb[:,1], cmap = 'magma', c = np.tile(np.arange(900),9), s=1)\n",
    "ax1.axis('off')\n",
    "\n",
    "ax2 = plt.subplot(122)\n",
    "ax2.set_title('Neuropixel')\n",
    "ax2.scatter(cebra_np_emb[:,0], cebra_np_emb[:,1], cmap = 'magma', c = np.tile(np.repeat(np.arange(900),4),9), s=1)\n",
    "ax2.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceddc6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_loader = cebra.data.ContinuousMultiSessionDataLoader(joint_train, num_steps = train_steps, batch_size = 512, conditional = 'time_delta', time_offset=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c372bd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "cebra_joint = multi_session_solver(data_loader = joint_loader, model_architecture = ['offset1-model', 'resample1-model'],\n",
    "                 distance = 'cosine', num_hidden_units = 128, output_dimension = 128,\n",
    "                verbose = True, device = DEVICE, temperature = 1, learning_rate = 3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22357140",
   "metadata": {},
   "outputs": [],
   "source": [
    "cebra_joint.fit(joint_loader)\n",
    "cebra_joint_embs = _compute_emissions_multi(cebra_joint, joint_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f7bba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (12,5))\n",
    "\n",
    "ax1 = plt.subplot(121)\n",
    "ax1.set_title('Ca, jointly trained')\n",
    "ax1.scatter(cebra_joint_embs[0][:,0], cebra_joint_embs[0][:,1], cmap = 'magma', c = np.tile(np.arange(900),9), s=1)\n",
    "ax1.axis('off')\n",
    "\n",
    "ax2 = plt.subplot(122)\n",
    "ax2.set_title('Neuropixel, jointly trained')\n",
    "ax2.scatter(cebra_joint_embs[1][:,0], cebra_joint_embs[1][:,1], cmap = 'magma', c = np.tile(np.repeat(np.arange(900),4),9), s=1)\n",
    "ax2.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a50b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def allen_frame_id_decode(train_fs, train_labels, test_fs, test_labels, modality = 'neuropixel', decoder = 'knn'):\n",
    "\n",
    "    if modality == 'neuropixel':\n",
    "        FACTOR = 4\n",
    "    elif modality == 'ca':\n",
    "        FACTOR = 1\n",
    "\n",
    "    time_window = 1\n",
    "\n",
    "    def feature_for_one_frame(feature):\n",
    "        if isinstance(feature, torch.Tensor):\n",
    "            feature = feature.cpu().numpy()\n",
    "        return feature.reshape(-1,FACTOR,feature.shape[-1]).mean(axis = 1)\n",
    "\n",
    "    train_fs = feature_for_one_frame(train_fs)\n",
    "    test_fs = feature_for_one_frame(test_fs)\n",
    "\n",
    "\n",
    "    if train_fs is None or test_fs is None:\n",
    "        return [None], [None], None\n",
    "    if decoder == 'knn':\n",
    "        params = np.power(np.linspace(1, 10, 5, dtype=int), 2)\n",
    "    elif decoder == 'bayes':\n",
    "        params = np.logspace(-9, 3, 5)\n",
    "    else:\n",
    "        raise ValueError('Choose decoder between knn or bayes')\n",
    "    errs = []\n",
    "\n",
    "    for n in params:\n",
    "        if decoder == 'knn':\n",
    "            train_decoder = KNeighborsClassifier(n_neighbors=n,\n",
    "                                                     metric='cosine')\n",
    "        elif decoder == 'bayes':\n",
    "            train_decoder = GaussianNB(var_smoothing = n)\n",
    "        train_valid_idx = int(len(train_fs)/9*8)\n",
    "        train_decoder.fit(train_fs[:train_valid_idx], train_labels[:train_valid_idx])\n",
    "        pred = train_decoder.predict(train_fs[train_valid_idx:])\n",
    "        err = train_labels[train_valid_idx:] - pred\n",
    "        errs.append(abs(err).sum())\n",
    "\n",
    "    if decoder == 'knn':\n",
    "        test_decoder = KNeighborsClassifier(n_neighbors=params[np.argmin(errs)],\n",
    "                                                     metric='cosine')\n",
    "    elif decoder == 'bayes':\n",
    "        test_decoder = GaussianNB(var_smoothing = params[np.argmin(errs)])\n",
    "\n",
    "    test_decoder.fit(train_fs, train_labels)\n",
    "    pred = test_decoder.predict(test_fs)\n",
    "    frame_errors = pred - test_labels\n",
    "\n",
    "    def _quantize_acc(frame_diff, time_window=1):\n",
    "\n",
    "        true = (abs(frame_diff) < (time_window * 30)).sum()\n",
    "\n",
    "        return true / len(frame_diff) * 100\n",
    "\n",
    "    quantized_acc = _quantize_acc(frame_errors, time_window)\n",
    "\n",
    "    return pred, frame_errors, quantized_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c0de81",
   "metadata": {},
   "outputs": [],
   "source": [
    "cebra_joint_test = _compute_emissions_multi(cebra_joint, joint_test)\n",
    "cebra_np_test = _compute_emissions_single(cebra_np, np_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547dcda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_loader_1frame = cebra.data.ContinuousDataLoader(ca_train, num_steps = train_steps, batch_size = 512, conditional = 'time_delta', time_offset =1)\n",
    "np_loader_1frame = cebra.data.ContinuousDataLoader(np_train, num_steps = train_steps, batch_size = 512, conditional = 'time_delta', time_offset = 1)\n",
    "\n",
    "cebra_ca_1frame = single_session_solver(data_loader = ca_loader, model_architecture = 'offset1-model',\n",
    "                 distance = 'cosine', num_hidden_units = 128, output_dimension = 128,\n",
    "                verbose = True, device = DEVICE, temperature = 1, learning_rate = 3e-4)\n",
    "\n",
    "cebra_np_1frame = single_session_solver(data_loader = np_loader, model_architecture = 'resample1-model',\n",
    "                 distance = 'cosine', num_hidden_units = 128, output_dimension = 128,\n",
    "                verbose = True, device = DEVICE, temperature = 1, learning_rate = 3e-4)\n",
    "\n",
    "joint_loader_1frame = cebra.data.ContinuousMultiSessionDataLoader(joint_train, num_steps = train_steps, batch_size = 512, conditional = 'time_delta', time_offset=1)\n",
    "cebra_joint_1frame = multi_session_solver(data_loader = joint_loader, model_architecture = ['offset1-model', 'resample1-model'],\n",
    "                 distance = 'cosine', num_hidden_units = 128, output_dimension = 128,\n",
    "                verbose = True, device = DEVICE, temperature = 1, learning_rate = 3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaec5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_knn, errs_knn, acc_knn =allen_frame_id_decode(np_train.neural, np.tile(np.arange(900), 9),\n",
    "                     np_test.neural, np.arange(900), modality = 'neuropixel', decoder = 'knn')\n",
    "\n",
    "pred_bayes, errs_bayes, acc_bayes=allen_frame_id_decode(np_train.neural, np.tile(np.arange(900), 9),\n",
    "                     np_test.neural, np.arange(900), modality = 'neuropixel', decoder = 'bayes')\n",
    "\n",
    "pred_cebra, errs_cebra ,acc_cebra = allen_frame_id_decode(cebra_np_emb, np.tile(np.arange(900), 9), cebra_np_test, np.arange(900), modality = 'neuropixel', decoder = 'knn')\n",
    "\n",
    "pred_joint_cebra, errs_joint_cebra, acc_joint_cebra = allen_frame_id_decode(cebra_joint_embs[1], np.tile(np.arange(900), 9), cebra_joint_test[1], np.arange(900),modality = 'neuropixel', decoder = 'knn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901774ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'kNN baseline: {acc_knn:.2f}%')\n",
    "print(f'Bayes baseline: {acc_bayes:.2f}%')\n",
    "print(f'CEBRA Neuropixel: {acc_cebra:.2f}%')\n",
    "print(f'joint CEBRA Neuropixel: {acc_joint_cebra:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dfb763",
   "metadata": {},
   "outputs": [],
   "source": [
    "cortex1 = 'VISp'\n",
    "cortex2 = 'VISrl'\n",
    "\n",
    "cortex1=cebra.datasets.init(f\"allen-movie-one-ca-neuropixel-{cortex1}-disjoint-0-400-train-10-{seed}\")\n",
    "cortex2=cebra.datasets.init(f\"allen-movie-one-ca-neuropixel-{cortex2}-disjoint-0-400-train-10-{seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10e153e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cortex1_loader = cebra.data.ContinuousMultiSessionDataLoader(cortex1, num_steps = 1000, batch_size = 512, conditional = 'time_delta', time_offset=10)\n",
    "cebra_cortex1 = multi_session_solver(data_loader = cortex1_loader, model_architecture = ['offset10-model', 'resample-model'],\n",
    "                 distance = 'cosine', num_hidden_units = 32, output_dimension = 32,\n",
    "                verbose = True, device = DEVICE, temperature = 1, learning_rate = 3e-4)\n",
    "\n",
    "cortex2_loader = cebra.data.ContinuousMultiSessionDataLoader(cortex2, num_steps = 1000, batch_size = 512, conditional = 'time_delta', time_offset=10)\n",
    "cebra_cortex2 = multi_session_solver(data_loader = cortex2_loader, model_architecture = ['offset10-model', 'resample-model'],\n",
    "                 distance = 'cosine', num_hidden_units = 32, output_dimension = 32,\n",
    "                verbose = True, device = DEVICE, temperature = 1, learning_rate = 3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c2308f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cebra_cortex1.fit(cortex1_loader)\n",
    "cebra_cortex2.fit(cortex2_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9109efa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cebra_cortex1_embs = _compute_emissions_multi(cebra_cortex1, cortex1)\n",
    "cebra_cortex2_embs = _compute_emissions_multi(cebra_cortex2, cortex2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce9d5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## A helper function to compute linear consistency\n",
    "def consistency(feature1, feature2):\n",
    "    if len(feature1) == 32400:\n",
    "        feature1 = feature1.reshape(-1, 4, feature1.shape[-1]).mean(axis=1)\n",
    "    if len(feature2) == 32400:\n",
    "        feature2 = feature2.reshape(-1, 4, feature2.shape[-1]).mean(axis=1)\n",
    "    def _linear_fit(a,b):\n",
    "        lin_model = LinearRegression()\n",
    "        lin_model.fit(a, b)\n",
    "        return lin_model.score(a, b)\n",
    "    return _linear_fit(feature1, feature2), _linear_fit(feature2, feature1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbd4632",
   "metadata": {},
   "outputs": [],
   "source": [
    "intra_cortices = consistency(cebra_cortex1_embs[0], cebra_cortex1_embs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8318d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_cortices = []\n",
    "for cortex1_emb in cebra_cortex1_embs.values():\n",
    "    for cortex2_emb in cebra_cortex2_embs.values():\n",
    "        inter_cortices.extend(consistency(cortex1_emb, cortex2_emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fd52b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Intra-area: {np.mean(intra_cortices):.2f}\")\n",
    "print(f\"Inter-area: {np.mean(inter_cortices):.2f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
